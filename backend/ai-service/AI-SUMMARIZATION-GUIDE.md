# ğŸ¤– HÆ¯á»šNG DáºªN: AI TÃ“M Táº®T THá»°C Sá»°

## â“ Váº¥n Ä‘á»

Hiá»‡n táº¡i chá»©c nÄƒng "TÃ³m táº¯t AI" **KHÃ”NG DÃ™NG AI tháº­t**, chá»‰ **copy y nguyÃªn** ná»™i dung tá»« Ä‘á» cÆ°Æ¡ng ra.

## âœ… Giáº£i phÃ¡p

ÄÃ£ cáº­p nháº­t code Ä‘á»ƒ sá»­ dá»¥ng **BARTpho** (AI model Tiáº¿ng Viá»‡t) Ä‘á»ƒ tÃ³m táº¯t vÄƒn báº£n thá»±c sá»±.

## ğŸ”§ CÃ¡c thay Ä‘á»•i Ä‘Ã£ thá»±c hiá»‡n

### 1. Backend AI Service (`backend/ai-service/app/workers/ai_handlers.py`)

**TrÆ°á»›c Ä‘Ã¢y:**
```python
def _summarize_text(self, text: str, max_sentences: int = 3) -> str:
    # Chá»‰ cáº¯t ngáº¯n text báº±ng cÃ¡ch láº¥y N cÃ¢u Ä‘áº§u tiÃªn
    sentences = text.split('. ')[:max_sentences]
    return '. '.join(sentences)
```

**BÃ¢y giá»:**
```python
def _summarize_text(self, text: str, max_length: int = 100) -> str:
    # Sá»­ dá»¥ng BARTpho AI model Ä‘á»ƒ tÃ³m táº¯t
    if not self.mock_mode and self.model is not None:
        inputs = self.tokenizer(text, max_length=512, truncation=True, return_tensors="pt")
        summary_ids = self.model.generate(
            inputs['input_ids'],
            max_length=max_length,
            num_beams=4,
            length_penalty=2.0,
            early_stopping=True
        )
        summary = self.tokenizer.decode(summary_ids[0], skip_special_tokens=True)
        return summary
    # Fallback náº¿u model khÃ´ng cÃ³
    return text[:200] + '...'
```

### 2. CÃ¡c pháº§n Ä‘Æ°á»£c tÃ³m táº¯t báº±ng AI

- âœ… **MÃ´ táº£ há»c pháº§n** - TÃ³m táº¯t tá»« text dÃ i â†’ 2-3 cÃ¢u ngáº¯n gá»n
- âœ… **Má»¥c tiÃªu há»c pháº§n** - Má»—i má»¥c tiÃªu Ä‘Æ°á»£c tÃ³m táº¯t gá»n láº¡i
- âœ… **CLO descriptions** - MÃ´ táº£ CLO Ä‘Æ°á»£c tÃ³m táº¯t
- âœ… **TiÃªu chÃ­ Ä‘Ã¡nh giÃ¡** - Criteria trong ma tráº­n Ä‘Ã¡nh giÃ¡ Ä‘Æ°á»£c rÃºt gá»n

### 3. ThÃªm cÃ¡c field má»›i

- âœ… **Ma tráº­n Ä‘Ã¡nh giÃ¡** (Assessment Matrix)
- âœ… **CLO** (Chuáº©n Ä‘áº§u ra há»c pháº§n)
- âœ… **PhÆ°Æ¡ng phÃ¡p Ä‘Ã¡nh giÃ¡** (tá»« database)

## ğŸš€ CÃ¡ch sá»­ dá»¥ng

### Option 1: Cháº¡y script tá»± Ä‘á»™ng

```powershell
# Tá»« thÆ° má»¥c root cá»§a project
.\restart-ai-with-model.ps1
```

Script nÃ y sáº½:
1. Kiá»ƒm tra vÃ  cÃ i Ä‘áº·t dependencies
2. Stop cÃ¡c worker cÅ©
3. Start worker má»›i vá»›i AI model

### Option 2: Manual restart

```powershell
cd backend\ai-service
.\venv\Scripts\Activate.ps1

# CÃ i Ä‘áº·t dependencies (chá»‰ láº§n Ä‘áº§u)
pip install transformers torch sentencepiece protobuf

# Start worker
python -m app.workers.ai_worker
```

## ğŸ“Š CÃ¡ch kiá»ƒm tra AI Ä‘ang cháº¡y

Khi start worker, kiá»ƒm tra log Ä‘á»ƒ tháº¥y:

```
ğŸ“¦ Loading model: vinai/bartpho-word
ğŸ”§ Using device: cpu
âœ… Model loaded successfully on cpu
```

Náº¿u tháº¥y:
```
âš ï¸ Using MOCK data (AI model not available)
```
â†’ AI model chÆ°a Ä‘Æ°á»£c load, cáº§n kiá»ƒm tra láº¡i config

## âš™ï¸ Configuration

File: `backend/ai-service/.env`

```bash
# Báº¬T AI MODEL
MOCK_MODE=false           # false = dÃ¹ng AI tháº­t
AI_MODEL_ENABLED=true     # true = load model

# Model name
AI_MODEL_NAME=vinai/bartpho-word  # BARTpho ~420MB
AI_MODEL_DEVICE=cpu               # cpu hoáº·c cuda
AI_MODEL_MAX_LENGTH=1024
```

## ğŸ“¦ AI Models cÃ³ sáºµn

| Model | Size | Cháº¥t lÆ°á»£ng | KhuyÃªn dÃ¹ng |
|-------|------|------------|-------------|
| `vinai/bartpho-word` | ~420MB | Tá»‘t | â­ Recommended |
| `VietAI/vit5-base` | ~900MB | Trung bÃ¬nh | Cháº­m hÆ¡n |
| `vinai/bartpho-syllable` | ~420MB | Tá»‘t | Alternative |

## ğŸ§ª Test AI summarization

1. **Restart AI worker** vá»›i AI model enabled
2. **VÃ o trang Student** â†’ Chá»n má»™t Ä‘á» cÆ°Æ¡ng
3. **Nháº¥n "TÃ³m táº¯t AI"**
4. **Kiá»ƒm tra káº¿t quáº£:**
   - MÃ´ táº£ há»c pháº§n pháº£i **ngáº¯n hÆ¡n** báº£n gá»‘c
   - Má»¥c tiÃªu pháº£i Ä‘Æ°á»£c **tÃ³m táº¯t gá»n**
   - CLO descriptions pháº£i **rÃºt gá»n**

## ğŸ› Troubleshooting

### Váº¥n Ä‘á»: Váº«n tháº¥y text y nguyÃªn, khÃ´ng tÃ³m táº¯t

**NguyÃªn nhÃ¢n:** Model chÆ°a Ä‘Æ°á»£c load hoáº·c Ä‘ang cháº¡y á»Ÿ MOCK mode

**Giáº£i phÃ¡p:**
```powershell
# 1. Kiá»ƒm tra .env
cat backend\ai-service\.env | Select-String "MOCK_MODE"
cat backend\ai-service\.env | Select-String "AI_MODEL_ENABLED"

# Pháº£i tháº¥y:
# MOCK_MODE=false
# AI_MODEL_ENABLED=true

# 2. Restart worker vÃ  xem log
cd backend\ai-service
python -m app.workers.ai_worker

# Pháº£i tháº¥y: "âœ… Model loaded successfully"
```

### Váº¥n Ä‘á»: Download model quÃ¡ lÃ¢u

**NguyÃªn nhÃ¢n:** Láº§n Ä‘áº§u tiÃªn táº£i model tá»« HuggingFace

**Giáº£i phÃ¡p:** Äá»£i 2-5 phÃºt, model sáº½ Ä‘Æ°á»£c cache táº¡i `~/.cache/huggingface/`

### Váº¥n Ä‘á»: Out of memory

**NguyÃªn nhÃ¢n:** Model quÃ¡ lá»›n cho RAM

**Giáº£i phÃ¡p:** 
- DÃ¹ng model nhá» hÆ¡n: `VietAI/vit5-base`
- Hoáº·c giá»¯ `MOCK_MODE=false` Ä‘á»ƒ dÃ¹ng simple summarization

## ğŸ“ Summary

| TrÆ°á»›c | Sau |
|-------|-----|
| âŒ Copy text y nguyÃªn | âœ… TÃ³m táº¯t báº±ng AI |
| âŒ KhÃ´ng cÃ³ CLO, Ma tráº­n | âœ… Hiá»ƒn thá»‹ Ä‘áº§y Ä‘á»§ |
| âŒ KhÃ´ng dÃ¹ng AI model | âœ… DÃ¹ng BARTpho model |
| âŒ Text quÃ¡ dÃ i | âœ… RÃºt gá»n 50-70% |

## ğŸ“ Support

Náº¿u cÃ³ váº¥n Ä‘á», kiá»ƒm tra:
1. Log cá»§a AI worker
2. File `.env` cÃ³ Ä‘Ãºng config khÃ´ng
3. Dependencies Ä‘Ã£ cÃ i Ä‘á»§ chÆ°a (`transformers`, `torch`, `sentencepiece`)
