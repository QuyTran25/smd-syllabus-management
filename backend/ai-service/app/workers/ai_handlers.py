"""
AI Message Handler
Xá»­ lÃ½ messages tá»« RabbitMQ vÃ  route tá»›i handlers tÆ°Æ¡ng á»©ng
"""
import logging
import time
import json
from datetime import datetime
from typing import Dict, Any
import os

# AI Model imports
try:
    from transformers import (
        AutoTokenizer, 
        AutoModelForSeq2SeqLM,
        BartForConditionalGeneration,
        AutoModelForCausalLM
    )
    import torch
    AI_AVAILABLE = True
except ImportError:
    AI_AVAILABLE = False
    logging.warning("âš ï¸ AI libraries not installed. Running in MOCK mode.")

logger = logging.getLogger(__name__)


class AIMessageHandler:
    """Handler chÃ­nh cho AI messages"""
    
    def __init__(self, rabbitmq_manager=None):
        """
        Initialize handler with AI model for SUMMARIZE function
        """
        self.mock_mode = os.getenv('MOCK_MODE', 'false').lower() == 'true'
        self.model = None
        self.tokenizer = None
        self.device = None
        self.rabbitmq_manager = rabbitmq_manager
        
        # Load AI model for SUMMARIZE if not in mock mode
        if not self.mock_mode and AI_AVAILABLE:
            try:
                self._load_summarize_model()
            except Exception as e:
                logger.error(f"âŒ Failed to load AI model: {e}")
                logger.warning("âš ï¸ Falling back to MOCK mode")
                self.mock_mode = True
        
        mode = "MOCK" if self.mock_mode else "AI"
        logger.info(f"ðŸ¤– AI Message Handler initialized in {mode} mode")
    
    def handle_message(self, message: Dict[str, Any]) -> Dict[str, Any]:
        """
        Route message tá»›i handler phÃ¹ há»£p dá»±a trÃªn action
        
        Args:
            message: Message dict tá»« RabbitMQ (format: AIMessageRequest)
            
        Returns:
            Response dict vá»›i status vÃ  result (format: AIMessageResponse)
        """
        action = message.get('action')
        message_id = message.get('messageId') or message.get('message_id')  # Support both formats
        payload = message.get('payload', {})
        priority = message.get('priority', 'MEDIUM')
        user_id = message.get('userId') or message.get('user_id')
        
        start_time = datetime.now()
        
        try:
            logger.info(f"[Received] Action: {action} for Message ID: {message_id}")
            logger.info(f"[Priority] {priority} | User: {user_id}")
            mode_status = "MOCK mode" if self.mock_mode else "AI mode"
            logger.info(f"[Processing] {action} with {mode_status}...")
            
            # Route to appropriate handler
            if action == 'MAP_CLO_PLO':
                result = self._handle_map_clo_plo(message_id, payload)
            elif action == 'COMPARE_VERSIONS':
                result = self._handle_compare_versions(message_id, payload)
            elif action == 'SUMMARIZE_SYLLABUS':
                result = self._handle_summarize(message_id, payload)
            else:
                raise ValueError(f"Unknown action: {action}")
            
            processing_time = int((datetime.now() - start_time).total_seconds() * 1000)
            
            response = {
                'messageId': message_id,
                'action': action,
                'status': 'SUCCESS',
                'progress': 100,
                'result': result,
                'processingTimeMs': processing_time
            }
            
            logger.info(f"[Done] Processing completed.")
            logger.info(f"âœ… {action} completed in {processing_time}ms")
            
            # TODO: LÆ°u result vÃ o DB (ai_service.syllabus_ai_analysis)
            # self._save_to_database(message_id, action, result, processing_time)
            
            # Send result to result queue
            self._send_result_to_queue(response)
            
            return response
            
        except Exception as e:
            logger.error(f"âŒ Error handling {action}: {e}", exc_info=True)
            
            processing_time = int((datetime.now() - start_time).total_seconds() * 1000)
            
            # Error response
            error_response = {
                'messageId': message_id,
                'action': action,
                'status': 'ERROR',
                'progress': 0,
                'result': None,
                'errorMessage': str(e),
                'processingTimeMs': processing_time
            }
            
            # Send error to result queue
            self._send_result_to_queue(error_response)
            
            return error_response
    
    def _send_result_to_queue(self, response: Dict[str, Any]) -> None:
        """Send result to ai_result_queue"""
        if not self.rabbitmq_manager:
            logger.warning("âš ï¸ No RabbitMQ manager, skipping result publish")
            return
        
        try:
            result_queue = os.getenv('QUEUE_AI_RESULT', 'ai_result_queue')
            success = self.rabbitmq_manager.publish_message(result_queue, response)
            if success:
                logger.info(f"ðŸ“¤ Result sent to {result_queue}: {response.get('messageId')}")
            else:
                logger.error(f"âŒ Failed to send result to {result_queue}")
        except Exception as e:
            logger.error(f"âŒ Error sending result: {e}", exc_info=True)
    
    def _handle_map_clo_plo(self, message_id: str, payload: Dict) -> Dict:
        """
        Handler cho MAP_CLO_PLO - Kiá»ƒm tra tuÃ¢n thá»§ CLO-PLO
        
        MOCK DATA - Tráº£ vá» structure giá»‘ng tháº­t Ä‘á»ƒ test workflow
        """
        syllabus_id = payload.get('syllabus_id')
        curriculum_id = payload.get('curriculum_id')
        
        logger.info(f"ðŸ“Š Analyzing CLO-PLO mapping for syllabus: {syllabus_id}")
        
        # Simulate AI processing time
        time.sleep(2)  # 2 seconds
        
        # MOCK RESULT - ÄÃºng format theo káº¿ hoáº¡ch
        result = {
            "overall_status": "NEEDS_IMPROVEMENT",
            "compliance_score": 75.5,
            "issues": [
                {
                    "severity": "HIGH",
                    "type": "MISSING_PLO_MAPPING",
                    "code": "PLO2",
                    "title": "PLO2: CLO chÆ°a Ã¡nh xáº¡ Ä‘á»§ sang PLO2 (yÃªu cáº§u tá»‘i thiá»ƒu 2 CLO)",
                    "description": "Hiá»‡n táº¡i chá»‰ cÃ³ 1 CLO Ã¡nh xáº¡ sang PLO2, cáº§n thÃªm Ã­t nháº¥t 1 CLO ná»¯a",
                    "current_count": 1,
                    "required_count": 2,
                    "affected_clos": ["CLO-1"]
                },
                {
                    "severity": "MEDIUM",
                    "type": "INSUFFICIENT_WEIGHT",
                    "code": "PLO5",
                    "title": "PLO5: Thiáº¿u Ä‘Ã¡nh giÃ¡ ká»¹ nÄƒng lÃ m viá»‡c nhÃ³m cho PLO5",
                    "description": "PLO5 yÃªu cáº§u ká»¹ nÄƒng lÃ m viá»‡c nhÃ³m nhÆ°ng chá»‰ cÃ³ 5% trá»ng sá»‘ trong Ä‘Ã¡nh giÃ¡ (khuyáº¿n nghá»‹ 10-15%)",
                    "current_weight": 5,
                    "recommended_weight": "10-15",
                    "affected_assessments": ["BÃ i táº­p nhÃ³m"]
                }
            ],
            "suggestions": [
                {
                    "priority": 1,
                    "action": "ADD_CLO",
                    "title": "ThÃªm CLO vá» ká»¹ nÄƒng phÃ¢n tÃ­ch dá»¯ liá»‡u á»©ng PLO2",
                    "description": "VÃ­ dá»¥: 'Sinh viÃªn cÃ³ kháº£ nÄƒng phÃ¢n tÃ­ch yÃªu cáº§u vÃ  thiáº¿t káº¿ mÃ´ hÃ¬nh dá»¯ liá»‡u phÃ¹ há»£p'"
                },
                {
                    "priority": 2,
                    "action": "ADJUST_WEIGHT",
                    "title": "Bá»• sung phÆ°Æ¡ng phÃ¡p Ä‘Ã¡nh giÃ¡ nhÃ³m (weight 10-15%) cho PLO5",
                    "description": "TÄƒng trá»ng sá»‘ bÃ i táº­p nhÃ³m tá»« 5% lÃªn 15%"
                },
                {
                    "priority": 3,
                    "action": "REVIEW_CONSISTENCY",
                    "title": "Xem xÃ©t tÄƒng trá»ng sá»‘ CLO Ã¡nh xáº¡ sang PLO2 lÃªn Ã­t nháº¥t 30%",
                    "description": "Äáº£m báº£o táº§m quan trá»ng cá»§a PLO2 Ä‘Æ°á»£c pháº£n Ã¡nh qua assessment scheme"
                }
            ],
            "compliant_mappings": [
                {
                    "plo_code": "PLO1",
                    "mapped_clos": ["CLO-1", "CLO-2", "CLO-3"],
                    "total_weight": 45,
                    "status": "GOOD"
                },
                {
                    "plo_code": "PLO3",
                    "mapped_clos": ["CLO-4", "CLO-5"],
                    "total_weight": 35,
                    "status": "GOOD"
                }
            ]
        }
        
        logger.info(f"âœ… CLO-PLO analysis completed. Status: {result['overall_status']}")
        return result
    
    def _handle_compare_versions(self, message_id: str, payload: Dict) -> Dict:
        """
        Handler cho COMPARE_VERSIONS - So sÃ¡nh phiÃªn báº£n
        
        MOCK DATA
        """
        old_version_id = payload.get('old_version_id')
        new_version_id = payload.get('new_version_id')
        
        logger.info(f"ðŸ” Comparing versions: {old_version_id} â†’ {new_version_id}")
        
        time.sleep(3)  # 3 seconds
        
        # MOCK RESULT
        result = {
            "is_first_version": False,
            "version_history": [
                {
                    "version_number": "NaN",
                    "status": "Hiá»‡n táº¡i",
                    "created_by": "Tráº§n Thá»‹ Lan",
                    "created_at": "02/01/2026 08:24",
                    "is_current": True
                },
                {
                    "version_number": "NaN",
                    "status": "PhiÃªn báº£n NaN",
                    "created_by": "Tráº§n Thá»‹ Lan",
                    "created_at": "30/12/2025 16:20",
                    "is_current": False
                }
            ],
            "changes_summary": {
                "total_changes": 3,
                "major_changes": 2,
                "minor_changes": 1,
                "sections_affected": ["learning_outcomes", "assessment_scheme", "references"]
            },
            "detailed_changes": [
                {
                    "section": "learning_outcomes",
                    "section_title": "Má»¥c tiÃªu há»c táº­p",
                    "change_type": "MODIFIED",
                    "changes": [
                        {
                            "field": "CLO 1",
                            "old_value": "Sinh viÃªn hiá»ƒu cÃ¡c khÃ¡i niá»‡m cÆ¡ báº£n vá» CSDL",
                            "new_value": "Sinh viÃªn náº¯m vá»¯ng vÃ  Ã¡p dá»¥ng Ä‘Æ°á»£c cÃ¡c khÃ¡i niá»‡m cÆ¡ báº£n vá» CSDL",
                            "significance": "HIGH",
                            "impact": "TÄƒng má»©c Ä‘á»™ yÃªu cáº§u tá»« 'hiá»ƒu' lÃªn 'Ã¡p dá»¥ng'"
                        }
                    ]
                }
            ],
            "ai_analysis": {
                "overall_assessment": "PhiÃªn báº£n má»›i cÃ³ cáº£i thiá»‡n Ä‘Ã¡ng ká»ƒ vá» CLO vÃ  phÆ°Æ¡ng phÃ¡p Ä‘Ã¡nh giÃ¡",
                "key_improvements": [
                    "CLO Ä‘Æ°á»£c nÃ¢ng cáº¥p tá»« má»©c Ä‘á»™ 'hiá»ƒu' lÃªn 'Ã¡p dá»¥ng', phÃ¹ há»£p vá»›i PLO",
                    "ThÃªm bÃ i táº­p nhÃ³m giÃºp phÃ¡t triá»ƒn ká»¹ nÄƒng lÃ m viá»‡c nhÃ³m"
                ],
                "recommendations": [
                    "CÃ¢n nháº¯c bá»• sung rubric chi tiáº¿t cho bÃ i táº­p nhÃ³m"
                ]
            }
        }
        
        logger.info(f"âœ… Version comparison completed")
        return result
    
    def _handle_summarize(self, message_id: str, payload: Dict) -> Dict:
        """
        Handler cho SUMMARIZE_SYLLABUS - TÃ³m táº¯t cho sinh viÃªn
        
        Sá»­ dá»¥ng AI model tháº­t (VietAI/vit5-base) Ä‘á»ƒ tÃ³m táº¯t
        """
        syllabus_id = payload.get('syllabus_id')
        syllabus_data = payload.get('syllabus_data', {})
        
        logger.info(f"ðŸ“ Summarizing syllabus: {syllabus_id}")
        
        # Use real AI if available
        if not self.mock_mode and self.model is not None:
            return self._summarize_with_ai(syllabus_data)
        
        # Fallback to mock
        logger.info("âš ï¸ Using MOCK data (AI model not available)")
        time.sleep(2)  # 2 seconds
        
        # MOCK RESULT
        result = {
            "overview": {
                "title": "Thiáº¿t káº¿ vÃ  tá»‘i Æ°u hÃ³a CSDL",
                "description": "MÃ´n há»c trang bá»‹ kiáº¿n thá»©c vá» thiáº¿t káº¿ CSDL quan há»‡, chuáº©n hÃ³a, vÃ  tá»‘i Æ°u truy váº¥n"
            },
            "highlights": {
                "difficulty": {
                    "level": "MEDIUM",
                    "description": "Trung bÃ¬nh - PhÃ¹ há»£p sinh viÃªn nÄƒm 2-3"
                },
                "duration": {
                    "theory_hours": 30,
                    "practice_hours": 30,
                    "total_hours": 60,
                    "description": "30 lÃ½ thuyáº¿t + 30 tiáº¿t thá»±c hÃ nh"
                },
                "assessment": {
                    "summary": "CÃ¢n báº±ng giá»¯a thi vÃ  bÃ i táº­p/dá»± Ã¡n",
                    "breakdown": [
                        {"type": "Thi giá»¯a ká»³", "weight": 30},
                        {"type": "BÃ i táº­p", "weight": 20},
                        {"type": "Dá»± Ã¡n", "weight": 20},
                        {"type": "Thi cuá»‘i ká»³", "weight": 30}
                    ]
                },
                "skills_acquired": {
                    "summary": "Ãnh xáº¡ CLO tá»›i PLO rÃµ rÃ ng",
                    "key_skills": [
                        "Thiáº¿t káº¿ ERD vÃ  chuáº©n hÃ³a CSDL",
                        "Viáº¿t truy váº¥n SQL phá»©c táº¡p",
                        "Tá»‘i Æ°u hiá»‡u nÄƒng database"
                    ]
                }
            },
            "recommendations": {
                "prerequisites": {
                    "required": ["Cáº¥u trÃºc dá»¯ liá»‡u vÃ  giáº£i thuáº­t", "OOP"],
                    "description": "NÃªn cÃ³ kiáº¿n thá»©c cÆ¡ báº£n vá» cÃ¡c mÃ´n tiÃªn quyáº¿t"
                },
                "preparation": {
                    "tips": [
                        "Ã”n láº¡i kiáº¿n thá»©c ná»n vá» cáº¥u trÃºc dá»¯ liá»‡u",
                        "LÃ m quen vá»›i SQL cÆ¡ báº£n",
                        "CÃ i Ä‘áº·t PostgreSQL/MySQL trÆ°á»›c khi há»c"
                    ],
                    "description": "Chuáº©n bá»‹ trÆ°á»›c: Ã”n láº¡i kiáº¿n thá»©c ná»n"
                },
                "study_time": {
                    "hours_per_week": 6,
                    "breakdown": "4 giá» lÃ m bÃ i táº­p + 2 giá» Ä‘á»c tÃ i liá»‡u",
                    "description": "DÃ nh Ã­t nháº¥t 6 giá»/tuáº§n"
                }
            }
        }
        
        logger.info(f"âœ… Summarization completed")
        return result
    
    # =============================================
    # AI MODEL METHODS - REAL IMPLEMENTATION
    # =============================================
    
    def _load_summarize_model(self):
        """
        Load VinAI/bartpho-word model cho summarization
        BART Vietnamese - Tá»‘t hÆ¡n cho Vietnamese text generation
        """
        model_name = os.getenv('AI_MODEL_NAME', 'vinai/bartpho-word')
        logger.info(f"ðŸ“¦ Loading model: {model_name}")
        
        # Determine device
        self.device = "cuda" if torch.cuda.is_available() else "cpu"
        logger.info(f"ðŸ”§ Using device: {self.device}")
        
        # Load tokenizer
        self.tokenizer = AutoTokenizer.from_pretrained(model_name)
        
        # Load model - BART architecture
        self.model = BartForConditionalGeneration.from_pretrained(
            model_name,
            torch_dtype=torch.float16 if self.device == "cuda" else torch.float32
        ).to(self.device)
        
        logger.info(f"âœ… Model loaded successfully on {self.device}")
    
    def _summarize_with_ai(self, syllabus_data: Dict) -> Dict:
        """
        Táº¡o tÃ³m táº¯t cÃ³ cáº¥u trÃºc tá»« dá»¯ liá»‡u Ä‘á» cÆ°Æ¡ng theo format chuáº©n
        """
        try:
            # Extract syllabus information
            course_name = syllabus_data.get('course_name', 'N/A')
            description = syllabus_data.get('description', '')
            learning_outcomes = syllabus_data.get('learning_outcomes', [])
            assessment_scheme = syllabus_data.get('assessment_scheme', [])
            objectives = syllabus_data.get('objectives', [])
            theory_hours = syllabus_data.get('theory_hours', 0)
            practice_hours = syllabus_data.get('practice_hours', 0)
            prerequisites = syllabus_data.get('prerequisites', [])
            textbooks = syllabus_data.get('textbooks', [])
            references = syllabus_data.get('references', [])
            weekly_content = syllabus_data.get('weekly_content', [])
            
            # 1. MÃ´ táº£ há»c pháº§n
            mo_ta = description if description else "KhÃ´ng cÃ³ thÃ´ng tin"
            
            # 2. Má»¥c tiÃªu há»c pháº§n
            muc_tieu = []
            if objectives:
                # Check if objectives is a list or string
                if isinstance(objectives, list):
                    for obj in objectives:
                        obj_text = obj if isinstance(obj, str) else str(obj)
                        if obj_text:
                            muc_tieu.append(obj_text)
                elif isinstance(objectives, str):
                    # If it's a string, split by common delimiters or add as single item
                    if '\n' in objectives:
                        muc_tieu = [o.strip() for o in objectives.split('\n') if o.strip()]
                    elif '. ' in objectives:
                        muc_tieu = [o.strip() + '.' for o in objectives.split('. ') if o.strip()]
                    else:
                        muc_tieu = [objectives]
            
            # 3. PhÆ°Æ¡ng phÃ¡p giáº£ng dáº¡y (tá»« weekly_content náº¿u cÃ³)
            phuong_phap_giang_day = []
            if weekly_content and len(weekly_content) > 0:
                for week in weekly_content[:3]:
                    if isinstance(week, dict):
                        activities = week.get('activities', '')
                        if activities and activities not in phuong_phap_giang_day:
                            phuong_phap_giang_day.append(activities)
            if not phuong_phap_giang_day:
                phuong_phap_giang_day = ["BÃ i giáº£ng trÃªn lá»›p", "Tháº£o luáº­n nhÃ³m", "BÃ i táº­p thá»±c hÃ nh"]
            
            # 4. PhÆ°Æ¡ng phÃ¡p Ä‘Ã¡nh giÃ¡
            phuong_phap_danh_gia = []
            if assessment_scheme and len(assessment_scheme) > 0:
                for assess in assessment_scheme:
                    if isinstance(assess, dict):
                        method = assess.get('method', '')
                        weight = assess.get('weight', '')
                        if method:
                            phuong_phap_danh_gia.append({
                                "method": method,
                                "weight": str(weight)
                            })
            
            # 5. GiÃ¡o trÃ¬nh chÃ­nh
            giao_trinh_chinh = []
            if textbooks and len(textbooks) > 0:
                for book in textbooks:
                    if isinstance(book, dict):
                        if book.get('type') == 'required':
                            giao_trinh_chinh.append({
                                "title": book.get('title', ''),
                                "authors": book.get('authors', ''),
                                "year": book.get('year', '')
                            })
            
            # 6. TÃ i liá»‡u tham kháº£o
            tai_lieu_tham_khao = []
            if textbooks and len(textbooks) > 0:
                for book in textbooks:
                    if isinstance(book, dict):
                        if book.get('type') == 'reference':
                            tai_lieu_tham_khao.append({
                                "title": book.get('title', ''),
                                "authors": book.get('authors', ''),
                                "year": book.get('year', '')
                            })
            if references and len(references) > 0:
                for ref in references:
                    ref_text = ref if isinstance(ref, str) else str(ref)
                    if ref_text:
                        tai_lieu_tham_khao.append({"title": ref_text})
            
            # 7. Nhiá»‡m vá»¥ cá»§a Sinh viÃªn
            nhiem_vu = []
            student_duties = syllabus_data.get('student_duties', '')
            if student_duties:
                # If data from database exists
                if isinstance(student_duties, str):
                    if '. ' in student_duties:
                        nhiem_vu = [nv.strip() + '.' for nv in student_duties.split('. ') if nv.strip()]
                    else:
                        nhiem_vu = [student_duties]
                elif isinstance(student_duties, list):
                    nhiem_vu = student_duties
            
            # If no data from database, generate generic template
            if not nhiem_vu:
                nhiem_vu = [
                    f"Tham gia Ä‘áº§y Ä‘á»§ {theory_hours + practice_hours} tiáº¿t há»c ({theory_hours} lÃ½ thuyáº¿t + {practice_hours} thá»±c hÃ nh)",
                    "HoÃ n thÃ nh cÃ¡c bÃ i táº­p Ä‘Æ°á»£c giao Ä‘Ãºng háº¡n",
                    "Tham gia tháº£o luáº­n vÃ  lÃ m viá»‡c nhÃ³m tÃ­ch cá»±c",
                    "Chuáº©n bá»‹ bÃ i trÆ°á»›c khi Ä‘áº¿n lá»›p"
                ]
            
            # 8. Chuáº©n Ä‘áº§u ra há»c pháº§n (CLO)
            clo_list = []
            if learning_outcomes and len(learning_outcomes) > 0:
                for clo in learning_outcomes:
                    if isinstance(clo, dict):
                        clo_list.append({
                            "code": clo.get('code', ''),
                            "description": clo.get('description', ''),
                            "bloom_level": clo.get('bloom_level', ''),
                            "weight": str(clo.get('weight', ''))
                        })
            
            result = {
                "course_name": course_name,
                "mo_ta_hoc_phan": mo_ta,
                "muc_tieu_hoc_phan": muc_tieu,
                "phuong_phap_giang_day": phuong_phap_giang_day,
                "phuong_phap_danh_gia": phuong_phap_danh_gia,
                "giao_trinh_chinh": giao_trinh_chinh,
                "tai_lieu_tham_khao": tai_lieu_tham_khao,
                "nhiem_vu_sinh_vien": nhiem_vu,
                "clo": clo_list
            }
            
            logger.info("âœ… Structured Summary completed")
            logger.info(f"ðŸ“„ Result:\n{json.dumps(result, ensure_ascii=False, indent=2)}")
            return result
            
        except Exception as e:
            logger.error(f"âŒ Summary creation failed: {e}", exc_info=True)
            # Fallback to basic structured summary
            return self._create_structured_summary(syllabus_data)
    
    def _generate_summary(self, prompt: str, max_length: int = 150) -> str:
        """
        Generate summary using BARTpho
        """
        try:
            # Tokenize (BARTpho doesn't use token_type_ids)
            inputs = self.tokenizer(
                prompt,
                max_length=512,
                truncation=True,
                return_tensors="pt",
                add_special_tokens=True
            )
            # Remove token_type_ids if present (not used by BARTpho)
            if 'token_type_ids' in inputs:
                del inputs['token_type_ids']
            
            inputs = inputs.to(self.device)
            
            # Generate with better parameters for quality
            with torch.no_grad():
                outputs = self.model.generate(
                    **inputs,
                    max_length=max_length,
                    min_length=20,
                    num_beams=5,
                    no_repeat_ngram_size=3,
                    repetition_penalty=2.0,
                    length_penalty=1.0,
                    early_stopping=True
                )
            
            # Decode
            summary = self.tokenizer.decode(outputs[0], skip_special_tokens=True)
            return summary.strip()
            
        except Exception as e:
            logger.error(f"âŒ Generation failed: {e}")
            return prompt[:max_length]  # Fallback to truncated input
    
    def _format_learning_outcomes(self, outcomes: list) -> str:
        """Format learning outcomes for prompt"""
        if not outcomes:
            return "KhÃ´ng cÃ³ thÃ´ng tin"
        formatted = []
        for o in outcomes[:5]:
            if isinstance(o, dict):
                formatted.append(f"- {o.get('description', str(o))}")
            else:
                formatted.append(f"- {str(o)}")
        return "\n".join(formatted)
    
    def _format_assessment_scheme(self, scheme: list) -> str:
        """Format assessment scheme for prompt"""
        if not scheme:
            return "KhÃ´ng cÃ³ thÃ´ng tin"
        return "\n".join([f"- {s.get('type', 'N/A')}: {s.get('weight', 0)}%" for s in scheme])
    
    def _extract_highlights(self, syllabus_data: Dict) -> Dict:
        """Extract key highlights from syllabus data"""
        theory_hours = syllabus_data.get('theory_hours', 0)
        practice_hours = syllabus_data.get('practice_hours', 0)
        total_hours = theory_hours + practice_hours
        assessment_scheme = syllabus_data.get('assessment_scheme', [])
        learning_outcomes = syllabus_data.get('learning_outcomes', [])
        
        # Determine difficulty
        difficulty_level = "MEDIUM"
        if total_hours > 60:
            difficulty_level = "HIGH"
        elif total_hours < 30:
            difficulty_level = "EASY"
        
        return {
            "difficulty": {
                "level": difficulty_level,
                "description": f"{difficulty_level.capitalize()} - Tá»•ng {total_hours} tiáº¿t"
            },
            "duration": {
                "theory_hours": theory_hours,
                "practice_hours": practice_hours,
                "total_hours": total_hours,
                "description": f"{theory_hours} lÃ½ thuyáº¿t + {practice_hours} tiáº¿t thá»±c hÃ nh"
            },
            "assessment": {
                "summary": f"CÃ³ {len(assessment_scheme) if assessment_scheme else 0} phÆ°Æ¡ng phÃ¡p Ä‘Ã¡nh giÃ¡",
                "breakdown": assessment_scheme if assessment_scheme else []
            },
            "skills_acquired": {
                "summary": f"CÃ³ {len(learning_outcomes) if learning_outcomes else 0} káº¿t quáº£ há»c táº­p",
                "key_skills": [
                    o.get('description', str(o))[:100] if isinstance(o, dict) else str(o)[:100] 
                    for o in (learning_outcomes[:5] if learning_outcomes else [])
                ]
            }
        }
    
    def _generate_recommendations(self, syllabus_data: Dict) -> Dict:
        """Generate study recommendations"""
        prerequisites = syllabus_data.get('prerequisites', [])
        theory_hours = syllabus_data.get('theory_hours', 0)
        practice_hours = syllabus_data.get('practice_hours', 0)
        
        # Calculate study time
        total_hours = theory_hours + practice_hours
        hours_per_week = max(4, int(total_hours / 15 * 1.5))  # Assume 15 weeks
        
        return {
            "prerequisites": {
                "required": prerequisites if prerequisites else ["KhÃ´ng cÃ³ yÃªu cáº§u tiÃªn quyáº¿t"],
                "description": "NÃªn cÃ³ kiáº¿n thá»©c cÆ¡ báº£n vá» cÃ¡c mÃ´n tiÃªn quyáº¿t" if prerequisites else "KhÃ´ng yÃªu cáº§u tiÃªn quyáº¿t"
            },
            "preparation": {
                "tips": [
                    "Äá»c trÆ°á»›c syllabus vÃ  tÃ i liá»‡u tham kháº£o",
                    f"Chuáº©n bá»‹ {hours_per_week} giá» há»c má»—i tuáº§n",
                    "Tham gia Ä‘áº§y Ä‘á»§ cÃ¡c buá»•i thá»±c hÃ nh"
                ],
                "description": "Chuáº©n bá»‹ trÆ°á»›c khi há»c"
            },
            "study_time": {
                "hours_per_week": hours_per_week,
                "breakdown": f"{int(hours_per_week * 0.6)} giá» lÃ m bÃ i táº­p + {int(hours_per_week * 0.4)} giá» Ä‘á»c tÃ i liá»‡u",
                "description": f"DÃ nh Ã­t nháº¥t {hours_per_week} giá»/tuáº§n"
            }
        }
    
    def _create_structured_summary(self, syllabus_data: Dict) -> Dict:
        """Create structured summary without AI generation (fallback)"""
        course_name = syllabus_data.get('course_name', 'N/A')
        description = syllabus_data.get('description', 'KhÃ´ng cÃ³ mÃ´ táº£')
        
        return {
            "overview": {
                "title": course_name,
                "description": description[:200] if len(description) > 200 else description
            },
            "highlights": self._extract_highlights(syllabus_data),
            "recommendations": self._generate_recommendations(syllabus_data)
        }
    
    def _compare_embeddings_similarity(self, text1: str, text2: str) -> float:
        """
        ðŸš€ TODO: So sÃ¡nh semantic similarity giá»¯a 2 texts
        
        Example implementation:
        
        from sklearn.metrics.pairwise import cosine_similarity
        import numpy as np
        
        # Get embeddings
        emb1 = self._get_embeddings([text1])[0]
        emb2 = self._get_embeddings([text2])[0]
        
        # Calculate cosine similarity
        similarity = cosine_similarity(
            np.array(emb1).reshape(1, -1),
            np.array(emb2).reshape(1, -1)
        )[0][0]
        
        return float(similarity)
        """
        pass
